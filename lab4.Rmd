---
title: "lab4"
author: "Carolyn Zhao 480561916"
date: "2021/3/21"
output: html_document
---

```{r}
# ipak function: install and load multiple R packages.
# check to see if packages are installed. Install them if they are not, then load them into the R session.

ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

# usage
packages <- c("tidyverse","readxl","tibble","janitor","reshape2",
              "ggplot2","ggthemes","plotly","pheatmap","maps",
              "zoo","dendextend","proxy","DT")
ipak(packages)

```
```{r}
library(tidyverse)
library(readxl)
library(tibble)
library(janitor)
library(reshape2)
library(ggplot2)
library(ggthemes)
library(plotly)
library(pheatmap)
library(maps)
library(zoo)
library(dendextend)
library(proxy)
library(DT)
```



2.1 
a)
```{r}
intersect(colnames(price), unique(mobility$region))
countries <- c("Brazil", "Germany", "Australia", "United Kingdom", "Italy", "New Zealand",
"United States", "Spain", "Singapore", "India", "Japan", "Norway") 

mobility <- readxl::read_xlsx("Mobility_Select.xlsx")
price <- readxl::read_xlsx("2020_Country_Index.xlsx")
covid_full <- read.csv("owid-covid-data-20.csv")
```

b)
```{r}
class(covid_full$date)
covid_full$date <- as.Date(covid_full$date)
class(covid_full$date)
covid <- covid_full[covid_full$location %in% countries, ]
## covid <- covid_full %>% filter(covid_full$location %in% countries) ## Alternative
## Check
table(as.character(covid$location))  ## how to drop the zeros
```
c)
```{r}
colnames(mobility)[-c(1:3)] <- 
  janitor::excel_numeric_to_date(colnames(mobility)[-c(1:3)] %>% 
                                   as.numeric(), date_system = "modern") %>% 
  as.character()
```

d) 
```{r}
dates <- as.character(price$Date)
price <- price %>% dplyr::select(-Date)
sum(is.na(price))
```
```{r}
price <- price %>% tidyr::fill(everything(), .direction = "up")
price <- as.data.frame(price)
rownames(price) <- dates
```



2.2
a)
```{r}
g_hosp <- ggplot(covid, aes(x = date, y = hosp_patients, 
                            group = location, color = location)) +
  geom_line(lwd = 1) +
  theme_bw() +
  scale_color_tableau(palette = "Tableau 20") +
  ylab("Number of hospitalised patients") +
  labs(color = "Country/Region")
g_hosp
```
```{r}
plotly::ggplotly(g_hosp)
```

b)
```{r}
g_total <- ggplot(covid, 
                  aes(x = date, y = total_cases, 
                      group = location, color = location)) +
  geom_line(lwd = 1) +
  theme_bw() +
  scale_color_tableau(palette = "Tableau 20") +
  ylab("Number of total cases") +
  scale_y_continuous(labels = scales::comma) + # disable scientific notation
  scale_x_date(date_breaks = "1 month") +
  labs(color = "Country/Region") 
plotly::ggplotly(g_total)
```
c)
```{r}
g_new <- ggplot(covid, 
                aes(x = date, y = new_cases, 
                    group = location, color = location)) +
  geom_line(lwd = 1) +
  theme_bw() +
  scale_color_tableau(palette = "Tableau 20") +
  ylab("Number of new cases") +
  scale_y_continuous(labels = scales::comma) + # disable scientific notation
  scale_x_date(date_breaks = "1 month") +
  labs(color = "Country/Region") 
g_new
```

2.3
a)
```{r}

library(gganimate)
p <- ggplot(covid, 
            aes(x = date, 
                y = total_cases, 
                group = location, color = location)) +
  geom_line(lwd = 1) +
  geom_point(size = 2) +
  transition_reveal(date) + 
  coord_cartesian(clip = 'off') + 
  geom_text(aes(x = date + 0.1, label = location), hjust = 0) + 
  scale_color_tableau(palette = "Tableau 20") +
  theme_minimal() +
  ylab("") +
  xlab("") +
  labs(color = "Country/Region", title = "Number of total cases") +
  scale_x_date(date_labels = "%m-%d", date_breaks = "7 day") +
  scale_y_continuous(labels = scales::comma) +
  theme(text = element_text(size = 10), 
        axis.text.x = element_text(angle = 90),
        legend.position = "none",
        plot.margin=unit(c(1, 2, 1, 2),"cm"))  +
  view_follow() 
p
```

```{r}
library(magick)
anim <- animate(p, fps = 4)
magick::image_write(anim, path = "COVID19_health/COVID-19_world_timeseries.gif")
```

2.4 
a)
```{r}
world_map <- map_data("world2")

ggplot(world_map, aes(x = long, y = lat, group = group)) + 
  geom_polygon(fill = "white", colour = "gray") + 
  theme(legend.position = "bottom", aspect.ratio = 0.6) + 
  ggtitle("Map of World")

```

b)
```{r}
world_map <- world_map %>%
  mutate(region = replace(region, region == "UK","United Kingdom")) %>% 
  mutate(region = replace(region, region == "USA","United States"))

```

c)
```{r}
summary(covid_full$total_cases)
```

```{r}
breaks <- c(0, 10^c(1:8))
## max(covid_full$total_cases, na.rm=TRUE) < max(breaks) ## Make sure this return TRUE

world_map_with_data$total_cases[is.na(world_map_with_data$total_cases)] <- 0
world_map_with_data$total_cases_category <- 
  cut(as.numeric(world_map_with_data$total_cases),
      breaks,include.lowest = TRUE, right = FALSE, dig.lab=10)

reds_col <- RColorBrewer::brewer.pal(length(breaks) - 1, "Reds")
names(reds_col) <- levels(world_map_with_data$total_cases_category)

ggplot(world_map_with_data,  
       aes(x = long, y = lat, group = group, fill = total_cases_category)) +
  geom_polygon() +
  scale_fill_manual(values = reds_col) +
  xlab("") + ylab("") + ggtitle("Map of World") +
  theme_void() +
  theme(legend.position = "bottom", aspect.ratio = 0.6) +
  labs(title = paste('COVID19: Total number of cases'),
       subtitle = paste("Date:", specific_date), 
       fill = "")
```

d)
```{r}
## Merge the data
specific_date = "2020-12-31"
covid_full_day <- covid_full %>% dplyr::filter(date == specific_date)
world_map_with_data <- merge(world_map, covid_full_day, 
                             by.x = "region", by.y = "location",
                             all.x = TRUE)
world_map_with_data <- world_map_with_data[order(world_map_with_data$order), ]

## create breaks
summary(covid_full$total_vaccinations)
```

```{r}
breaks <- c(0, 10^c(2:7))
max(covid_full$total_vaccinations, na.rm=TRUE) < max(breaks)
```
```{r}
## Simple processing to remove NAs
world_map_with_data$total_vaccinations[is.na(world_map_with_data$total_vaccinations)] <- 0
world_map_with_data$total_vaccinations_category <-
  cut(as.numeric(world_map_with_data$total_vaccinations),
      breaks, include.lowest = TRUE, right = FALSE, dig.lab=10)

## Generate color scheme
green_col <- RColorBrewer::brewer.pal(length(breaks) - 1, "Greens")
names(green_col) <- levels(world_map_with_data$total_vaccinations_category )

## Graphs
ggplot(world_map_with_data, 
       aes(x = long, y = lat, group = group, fill = total_vaccinations_category)) +
  geom_polygon() +
  scale_fill_manual(values = green_col) +
  xlab("") + ylab("") +  ggtitle("Map of World") +
  theme_void() +
  theme(legend.position = "bottom", aspect.ratio = 0.6) +
  labs(title = paste('COVID19: Total number of vaccinations'),
       subtitle = paste("Date:", specific_date), 
       fill = "")
```

3.1
```{r}
covid_oz = covid_full[covid_full$location =="Australia", ]
```
```{r}
lowess(x = as.numeric(covid_oz$date), y =  covid_oz$new_cases, f = 0.01)
```
```{r}
wrapLowess <- function(y, f) {
  lowess_fit <- lowess(x = as.numeric(covid_oz$date), y =  y, f = f)
  lowess_fit$y
}
```

```{r}
fval = c(0.01, 0.05, 0.1, 0.3)
lowess_smooth <- sapply(fval, wrapLowess, y = covid_oz$new_cases)
```

sample code 1
```{r}
covid_oz = covid_full[covid_full$location =="Australia", ]
plot(covid_oz$date, covid_oz$new_cases, pch=18, cex=0.5, xlab="date", ylab="New cases")
lines(lowess(x = as.numeric(covid_oz$date), y =  covid_oz$new_cases, f = 0.01), col="red")
lines(lowess(x = as.numeric(covid_oz$date), y =  covid_oz$new_cases, f = 0.05), col="blue")
lines(lowess(x = as.numeric(covid_oz$date), y =  covid_oz$new_cases, f = 0.1), col="brown")
lines(lowess(x = as.numeric(covid_oz$date), y =  covid_oz$new_cases, f = 0.3), col="green")
fval = c(0.01, 0.05, 0.1, 0.3)
legend("topright", lwd=1, col=c("red", "blue", "brown", "green"), legend = paste("f", fval, sep="="))
```
sample code 2 
```{r}
wrapLowess <- function(data, f) {
  lowess_fit <- lowess(data, f = f)
  lowess_fit$y
}

fval = c(0.01, 0.05, 0.1, 0.3)
lowess_smooth <- sapply(fval, wrapLowess, data = covid_oz$new_cases)
colnames(lowess_smooth) = paste("f", fval, sep="=")

covid_oz_lowess  = cbind(covid_oz$date, covid_oz$new_cases, lowess_smooth)

plot_data <- melt(data.frame(date = covid_oz$date, nc = covid_oz$new_cases, lowess_smooth), id.var="date")
head(plot_data)
```
```{r}
ggplot(plot_data, aes(x = date, y = value)) +
  geom_point(data = subset(plot_data,variable=="nc"), colour = "grey") + 
  geom_line(data = subset(plot_data, variable!="nc"), aes(group=variable, colour=variable)) + 
  theme_bw() + ylab("Number of new cases") 
```

b)
```{r}
## moving average
wrapRollmean <- function(data, k = 10){
  zoo::rollmean(data, k = k, fill = NA)
}

## loess
wrapLoess <- function(data, x=1:length(data), span=0.1) {
  ind <- !is.na(data); loess_fit <- rep(NA, length(data))
  loess_fit[ind] <- loess(data ~ as.numeric(x), span = span)$fitted
  loess_fit 
}

## Savitzky-Golay smoothing filter. 
wrapSG <- function(data, p=3, n=60){
  ind <- !is.na(data); fit <- rep(NA, length(data))
  fit[ind] <- signal::sgolayfilt(data[ind], p = p, n = n)
  fit
}
```

sample code
```{r}
## apply various smoothers
sRollmean <- wrapRollmean(covid_oz$new_cases, k = 7)
sLowess <- wrapLowess(covid_oz$new_cases, f = 0.1)
sLoess <- wrapLoess(covid_oz$new_cases, x = covid_oz$date, span = 0.1)
sSavitzkyGolay <- wrapSG(covid_oz$new_cases, p = 3, n = 61)
covid_oz_smooth <- cbind(aveSmoother = sRollmean, Lowess = sLowess, Loess = sLoess, SavitzkyGolay = sSavitzkyGolay )

plot_data <- melt(data.frame(date = covid_oz$date, nc = covid_oz$new_cases, covid_oz_smooth), id.var="date")
## head(plot_data) ## Make sure you check out the data
ggplot(plot_data, aes(x = date, y = value)) +
  geom_point(data = subset(plot_data,variable=="nc"), colour = "grey") + 
  geom_line(data = subset(plot_data, variable!="nc"), aes(group=variable, colour=variable)) + 
  theme_bw() + ylab("Number of new cases") 
```

c)

```{r}
covid_list <- split(covid$new_cases, covid$location) 
names(covid_list)

covid_list <- split(covid$new_cases, covid$location, drop=TRUE) 
names(covid_list)
unlist(lapply(covid_list, length))

```

sample code 1 
```{r}
## Cleaning
covid$new_cases[covid$new_cases < 0] <- NA
covid_list <- split(covid$new_cases, covid$location, drop=TRUE) 
covid_dates <- split(covid$date, covid$location, drop=TRUE) 


## apply your selected smoother
new_cases_loess <- lapply(covid_list, wrapLoess, span = 0.1)
covid$new_cases_loess <- unlist(new_cases_loess)

## All the dots
b0 <- ggplot() + 
  geom_point(data = covid, 
             aes(x = date, y = new_cases, group = location, color = location), color = "grey") 
## b0

## Split the data using facet_wrap
b1 <- ggplot() + 
  geom_point(data = covid, 
             aes(x = date, y = new_cases, group = location, color = location), color = "grey") +
  facet_wrap(~location, scale = "free_y")
## b1

## Overlay the lines
b2 <-  ggplot() + 
  geom_point(data = covid, 
             aes(x = date, y = new_cases, group = location, color = location), color = "grey") +
  geom_line(data = covid,
            aes(x = date, y = new_cases_loess, group = location, color = location),
            lwd = 1, color = "red") + 
  facet_wrap(~location, scale = "free_y")
## b2

## Add the labels and adjust the ascetic
b2 +  
  theme_bw() +
  ylab("Number of cases") +
  scale_y_continuous(labels = scales::comma, trans = "log10") + 
  labs(color = "Country/Region") 
```
sample code 2 
```{r}
## apply your selected smoother
new_cases_SG <- lapply(covid_list, wrapSG, p = 2, n = 61)
covid$new_cases_SG <- unlist(new_cases_SG)

## All the dots
ggplot() + 
  geom_point(data = covid, 
             aes(x = date, y = new_cases, group = location, color = location), color = "grey") +
  geom_line(data = covid,
            aes(x = date, y = new_cases_SG, group = location, color = location),
            lwd = 1, color = "red") + 
  facet_wrap(~location, scale = "free_y") +
  theme_bw() +
  ylab("Number of cases") + xlab("Date") + 
  scale_y_continuous(labels = scales::comma, trans = "log10") + 
  labs(color = "Country/Region") 
```
3.2 
3.2.1
```{r}
new_case_matrix <- covid %>% 
  dplyr::select(location, date, new_cases) %>%
  pivot_wider(names_from = location, values_from = new_cases) %>%
  arrange(date) %>% 
  replace(is.na(.), 0) %>%
  as.data.frame()

rownames(new_case_matrix) <- new_case_matrix$date
new_case_matrix <- new_case_matrix %>% dplyr::select(-date)
```

3.2.2
Option A To scale your time series such that it ranges from 0 to 1 followed by using a Manhattan distance.
```{r}
new_case_matrix_norm <- apply(new_case_matrix, 2, function(x) x/sum(x))
new_case_matrix_norm_dist <- dist(t(new_case_matrix_norm), method = "manhattan")
hclust_res <- hclust(new_case_matrix_norm_dist, method="ward.D2")
hclust_cluster <- cutree(hclust_res, k = 3) %>% as.factor %>% as.data.frame 
```

Option B Use a correlation distance
```{r}
new_case_matrix_cor <- as.dist(1 - cor(new_case_matrix, use="pairwise.complete.obs"))
hclust_res_cor <- hclust(new_case_matrix_cor, method="ward.D2")
hclust_cluster_cor <- cutree(hclust_res_cor, k = 3)%>% as.factor %>% as.data.frame 
```

Option C What about using Euclidean distance instead of Manhattan distance, does it make a difference?
Sample code
```{r}
new_case_matrix_norm <- apply(new_case_matrix, 2, function(x) x/sum(x))
new_case_matrix_norm_dist <- dist(t(new_case_matrix_norm), method = "euclidean")
hclust_res_euclid <- hclust(new_case_matrix_norm_dist, method="ward.D2")
hclust_cluster_euclid <- cutree(hclust_res_euclid, k = 3)%>% as.factor %>% as.data.frame 
```

3.2.3 Step 3a: Data visualisation - individual

Option A: A quick look using at the tree.
```{r}
plot(hclust_res)
```
Option B: Using a heatmap
```{r}
hclust_cluster <- cutree(hclust_res, k = 3) %>% as.factor %>% as.data.frame 
colnames(hclust_cluster) = "clust_res"
pheatmap(t(new_case_matrix_norm), 
         cluster_cols = FALSE,
         main = "New cases",
         annotation_row = hclust_cluster,
         clustering_distance_rows = "manhattan",
         clustering_method = "ward.D2")
```
Option C1: Scatter plots in multiple panels
```{r}
## shapping it back to a long format
df_covid <- reshape2::melt(new_case_matrix_norm)
colnames(df_covid) <- c("date", "location", "norm_new_cases")
df_covid <- df_covid %>% mutate(date = as.Date(date))
df_covid$cluster <-  hclust_cluster[as.character(df_covid$location), 1]

ggplot() +
  geom_line(data = df_covid, aes(x = date, y = norm_new_cases, color = location)) +
  facet_wrap(~cluster, ncol = 1) +  ## argument scale allow you to adjust whether to have the same y-axis or not
  theme_bw() + ylab("Normalised values") + labs(title = "COVID new cases")
```

Option C2: Scatter plots in multiple panels (with different y-axis)
```{r}
ggplot() +
  geom_line(data = df_covid, aes(x = date, y = norm_new_cases, color = location)) +
  facet_wrap(~cluster, scales="free_y", ncol = 1) +  ## argument scale allow you to adjust whether to have the same y-axis or not
  theme_bw() + ylab("Normalised values") + labs(title = "COVID new cases")
```
Option D: Smooth data
```{r}
new_case_matrix_norm_smooth <- apply(new_case_matrix_norm, 2, wrapLoess, span=0.1)
rownames(new_case_matrix_norm_smooth) <- rownames(new_case_matrix_norm)
df_covid <- reshape2::melt(new_case_matrix_norm_smooth)
colnames(df_covid) <- c("date", "location", "norm_new_cases")
df_covid <- df_covid %>% mutate(date = as.Date(date))
df_covid$cluster <- hclust_cluster[as.character(df_covid$location), 1]

ggplot() +
  geom_line(data = df_covid, aes(x = date, y = norm_new_cases, color = location)) +
  facet_wrap(~cluster, scales="free_y", ncol = 1) +  ## argument scale allow you to adjust whether to have the same y-axis or not
  theme_bw() + ylab("Smooth and normalised values") + labs(title = "COVID daily new cases")
```
3.2.4 Step 3b: Data visualisation - comparative

```{r}
hclust_list = list(man = hclust_res, cor = hclust_res_cor, euclid = hclust_res_euclid)
hclust_list_3 = lapply(hclust_list, stats::cutree, k = 3)
pairs <- combn(names(hclust_list_3), 2)
ari <- apply(pairs, 2, function(x) 
  mclust::adjustedRandIndex(hclust_list_3[x[1]], 
                            hclust_list_3[x[2]]))
names(ari) <- paste0(pairs[1, ], "|", pairs[2, ])
ari
```

```{r}
## Convert hclust results to dendrogram 
dendlist_dist <-  lapply(hclust_list, as.dendrogram) 

dendlist(dendlist_dist$man, dendlist_dist$euclid) %>%
  untangle(method = "step1side") %>% # Find the best alignment layout
  tanglegram() 
```
```{r}
dendlist(dendlist_dist$man, dendlist_dist$cor) %>%
  untangle(method = "step1side") %>% # Find the best alignment layout
  tanglegram()
```
3.3.1 For the mobility data
```{r}
## Part 1, 2, 3, 4
mobility_matrix <- mobility %>% 
  dplyr::filter(mobility$region %in% countries) %>% 
  group_by(region) %>%  
  dplyr::summarise(across(where(is.numeric), ~ sum(.x, na.rm = TRUE))) %>%
  as.data.frame()

## Part 4
rownames(mobility_matrix) <- mobility_matrix$region
mobility_matrix <- mobility_matrix %>% dplyr::select(-region)
mobility_matrix <- t(mobility_matrix)

## Part 5
mobility_matrix_norm <- apply(mobility_matrix, 2, function(x) x - min(x))
mobility_matrix_norm <- apply(mobility_matrix_norm, 2, function(x) x/(max(x)-min(x)))

## Part 6
mobility_matrix_norm_dist <- dist(t(mobility_matrix_norm), method = "manhattan")

## Part 7
hclust_res_mobility <- hclust(mobility_matrix_norm_dist, method = "ward.D2")  
hclust_cluster_mobility <- stats::cutree(hclust_res_mobility, k = 3)
```

3.3.2 For the price data,
```{r}
## Part 1
price_matrix <- price[,countries]

## Part 2
price_matrix_norm <- apply(price_matrix, 2, function(x) x - min(x))
price_matrix_norm <- apply(price_matrix_norm, 2, function(x) x/(max(x) - min(x)))

## Part 3
price_matrix_norm_dist <- dist(t(price_matrix_norm), method = "manhattan")

## Part 4
hclust_res_price <- hclust(price_matrix_norm_dist, method = "ward.D2")  
hclust_cluster_price <- stats::cutree(hclust_res_price, k = 3) %>% as.factor %>% as.data.frame()
```

3.3.3 Generate the following graphics
```{r}
## Fig A
hclust_cluster_mobility <- stats::cutree(hclust_res_mobility, k = 3) %>% as.factor %>% as.data.frame()
figa <- pheatmap(t(price_matrix_norm), 
                 cluster_cols = FALSE,
                 main = "Figure A: Mobility indices",
                 annotation_row = hclust_cluster_mobility,
                 clustering_distance_rows = "manhattan",
                 clustering_method = "ward.D2")
```
```{r}
## Fig B
hclust_cluster_price <- stats::cutree(hclust_res_price, k = 3) %>% as.factor %>% as.data.frame()
figb <- pheatmap(t(mobility_matrix_norm), 
                 cluster_cols = FALSE,
                 main = "Figure B: price indices",
                 annotation_row = hclust_cluster_price,
                 clustering_distance_rows = "manhattan",
                 clustering_method = "ward.D2")
```

```{r}
## Fig C
df_mobility <- reshape2::melt(mobility_matrix_norm)
colnames(df_mobility) <- c("date", "location", "mobility")
df_mobility <- df_mobility %>% mutate(date = as.Date(date))
df_mobility$cluster <-  hclust_cluster_mobility[as.character(df_mobility$location), 1]
figc <- ggplot() +
  geom_line(data = df_mobility, aes(x = date, y = mobility, color = location)) +
  facet_wrap(~cluster, scale = "free_y", ncol = 1) +
  theme_bw() +ylab("Normalised indices") + labs(title = "Figure C: Mobility") 

## Fig D
mobility_matrix_norm_smooth <- apply(mobility_matrix_norm, 2, wrapLoess, span=0.1)
rownames(mobility_matrix_norm_smooth) <- rownames(mobility_matrix_norm)
df_mobility <- reshape2::melt(mobility_matrix_norm_smooth)
colnames(df_mobility) <- c("date", "location", "smoothNormMobility")
df_mobility <- df_mobility %>% mutate(date = as.Date(date))
df_mobility$cluster <- hclust_cluster_mobility[as.character(df_mobility$location), 1]

figd <- ggplot() +
  geom_line(data = df_mobility, aes(x = date, y = smoothNormMobility, color = location)) +
  facet_wrap(~cluster, scales="free_y", ncol = 1) +  ## argument scale allow you to adjust whether to have the same y-axis or not
  theme_bw() + ylab("Smooth and normalised values") + labs(title = "Figure D: Mobility")

## Fig E
price_matrix_norm_smooth <- apply(price_matrix_norm, 2, wrapLoess, span=0.1)
rownames(price_matrix_norm_smooth) <- rownames(price_matrix_norm)
df_price <- reshape2::melt(price_matrix_norm_smooth)
colnames(df_price) <- c("date", "location", "smoothNormprice")
df_price <- df_price %>% mutate(date = as.Date(date))
df_price$cluster <- hclust_cluster_price[as.character(df_price$location), 1]

fige <- ggplot() +
  geom_line(data = df_price, aes(x = date, y = smoothNormprice, color = location)) +
  facet_wrap(~cluster, scales="free_y", ncol = 1) +  ## argument scale allow you to adjust whether to have the same y-axis or not
  theme_bw() + ylab("Smooth and normalised values") + labs(title = "Figure E: price")

## Fig F
figf = dendlist(as.dendrogram(hclust_res_price), as.dendrogram(hclust_res_mobility)) %>%
  untangle(method = "step1side") %>% # Find the best alignment layout
  tanglegram(
    common_subtrees_color_branches = TRUE,
    main_left="Figure F: Comparing two dendrograms") 
```

```{r}
figc
```
```{r}
figd
```
```{r}
fige
```
```{r}
figf
```

4 
4.1
[Step 1] To merge all three datasets, we will need to ensure that each matrix has the same set of dates and countries. There are several methods for bringing together different data, and for this section, we will use dates and countries common to all three data sets. Such actions often result in a loss of information and should be. Given that this is time-series data, our decision here is probably sensible.

```{r}
date_index <- Reduce(intersect, list(rownames(price_matrix),
                                     rownames(new_case_matrix),
                                     rownames(mobility_matrix)))
price_matrix2 <- price_matrix[date_index, countries]
new_case_matrix2 <- new_case_matrix[date_index, countries]
mobility_matrix2 <- mobility_matrix[date_index, countries]
combined_matrix <- cbind(price_matrix2,
                         mobility_matrix2,
                         new_case_matrix2)
rownames(combined_matrix) <- date_index
tmp = colnames(combined_matrix)
data_type <- rep(c("price", "mobility", "newCase"), 
                  each = ncol(price_matrix_norm))
colnames(combined_matrix) <- paste(tmp, data_type, sep=":")
```

[Step 2] Min-max normalization or min-max scaling 
```{r}
scaleMinMax <- function(x){
    (x - min(x)) / (max(x) - min(x))
}

## Step 2: scaling
combined_matrix_norm <- as.data.frame(apply(combined_matrix, 2, scaleMinMax))
rownames(combined_matrix_norm ) <- rownames(combined_matrix)
```

[Step 3] Smooth all the times series data from the three datasets.
```{r}
## Step 3: Smoothing
combined_matrix_norm_s <- as.data.frame(apply(combined_matrix_norm, 2, wrapLowess, f = 0.1))
rownames(combined_matrix_norm_s) <- rownames(combined_matrix_norm)
```

[Step 4] 
```{r}
## Step 4: Smoothing
combined_matrix_norm_cosine_dist <- proxy::dist(t(combined_matrix_norm_s), method = "cosine")
hclust_combine_res <- hclust(combined_matrix_norm_cosine_dist, method = "ward.D2")
```

Sample code + (i) the clustering results

```{r}
plot(hclust_combine_res)
```
ii.the cosine dis-similarity matrix of the combined times-series matrix
```{r}
pheatmap(as.matrix(combined_matrix_norm_cosine_dist))
```

+ (iii) visualize the time series profile stratified by multiple channels.
```{r}
colors <- c("Mobility" = "firebrick", "price" = "navy", "COVID" = "darkgoldenrod")

## reshape mobility

df_mobility <- combined_matrix_norm %>% dplyr::select(contains("mobility")) %>% as.matrix() %>% reshape2::melt() %>% as.data.frame() %>% mutate(Var2 = as.factor(gsub(":mobility", "", Var2)), Var1=as.Date(Var1))
colnames(df_mobility) <- c("date", "location", "mobility")

df_price <- combined_matrix_norm %>% dplyr::select(contains("price")) %>% as.matrix() %>% reshape2::melt() %>% as.data.frame() %>% mutate(Var2 = as.factor(gsub(":price", "", Var2)), Var1=as.Date(Var1))
colnames(df_price) <- c("date", "location", "price")

df_covid <- combined_matrix_norm %>% dplyr::select(contains("newCase")) %>% as.matrix() %>% reshape2::melt() %>% as.data.frame() %>% mutate(Var2 = as.factor(gsub(":newCase", "", Var2)), Var1=as.Date(Var1))
colnames(df_covid) <- c("date", "location", "covid")

ggplot() +
  geom_line(data = df_mobility, aes(x = date, y = mobility, color="Mobility")) +
  geom_line(data = df_price, aes(x = date, y = price, color = "price")) +
  facet_wrap(~location, scale = "free_y") +
  theme_bw() + ylab("Normalised indices") +
  scale_color_manual(values = colors) 
```

```{r}
ggplot() +
  geom_line(data = df_covid, aes(x = date, y = covid, color = "COVID")) +
  geom_line(data = df_mobility, aes(x = date, y = mobility, color="Mobility")) +
  facet_wrap(~location, scale = "free_y") +
  theme_bw() + ylab("Normalised indices") +
  scale_color_manual(values = colors) 
```

[Step 5a] The code below checks lag of the date with lowest indices
```{r}
argmin_mobility <- apply(mobility_matrix, 2, which.min)
argmin_finance <- apply(price[,countries], 2, which.min)
argmin_date <- cbind(rownames(mobility_matrix)[argmin_mobility],
                     rownames(price)[argmin_finance])
day_diff <- as.Date(argmin_date[, 1]) - as.Date(argmin_date[, 2])
names(day_diff) <- countries
## day_diff
```

[Step 5b] Select Australia as an example, calculate the inner product optimsation.
```{r}
TS1_matrix = combined_matrix_norm %>% dplyr::select(contains("price"))
TS2_matrix = combined_matrix_norm %>% dplyr::select(contains("mobility"))
countryName = "Australia" 
countryID = grep(countryName, colnames(TS1_matrix))
windowsize = 20

ip_mobility_vector <- c()
for (j in 1:windowsize) {
  mobility_ts <- TS1_matrix[(j):nrow(TS1_matrix), countryID]
  prices_ts <- TS2_matrix[1:(nrow(TS2_matrix) - j + 1), countryID]
  ip_mobility <- 1 - proxy::dist(t(mobility_ts), t(prices_ts), method = "cosine")  
  ip_mobility_vector <- c(ip_mobility_vector, ip_mobility)
}

ip_price_vector <- c()
for(j in 1:20) {
  mobility_ts <- TS1_matrix[1:(nrow(TS1_matrix) - j + 1), countryID]
  prices_ts <- TS2_matrix[(j):nrow(TS1_matrix), countryID]
  ip_price <- 1 - proxy::dist(t(mobility_ts), t(prices_ts), method = "cosine")
  ip_price_vector <- c(ip_price_vector, ip_price)
  
}

idx <- which.max(c(ip_price_vector, ip_mobility_vector))
idx
```
[Step 5c] Write a function to calculate the lag for a given country and call this function lagEstimation. We encourage you to write your own function but if you are struggling, the code skeleton is provided below.
```{r}
TS1_matrix = combined_matrix_norm %>% dplyr::select(contains("price"))
TS2_matrix = combined_matrix_norm %>% dplyr::select(contains("mobility"))

lagEstimation <- function(country, TS1_matrix, TS2_matrix, windowsize=20)
{
  countryID = grep(country, colnames(TS1_matrix))
  
  ip_TS1_vector <- c()
  for (j in 1:windowsize) {
    ts1 <- TS1_matrix[(j):nrow(TS1_matrix), countryID]
    ts2 <- TS2_matrix[1:(nrow(TS2_matrix) - j + 1), countryID]
    ip_TS1 <- 1 - proxy::dist(t(ts1), t(ts2), method = "cosine")  
    ip_TS1_vector <- c(ip_TS1_vector, ip_TS1)
  } ## end for
  
  ip_TS2_vector <- c()
  for(j in 1:20) {
    ts1a <- TS1_matrix[1:(nrow(TS1_matrix) - j + 1), countryID]
    ts2a <- TS2_matrix[(j):nrow(TS1_matrix), countryID]
    ip_TS2 <- 1 - proxy::dist(t(ts1a), t(ts2a), method = "cosine")
    ip_TS2_vector <- c(ip_TS2_vector, ip_TS2)
  } ## end for
  
  which.max(c(ip_TS1_vector, ip_TS2_vector))
} ## end LagEstimation 
```

[Step 5d] Use the function from part [c] you can estimate the lag between mobility and price movement for all twelve countries.
```{r}
TS1_matrix = combined_matrix_norm_s %>% dplyr::select(contains("price"))
TS2_matrix = combined_matrix_norm_s %>% dplyr::select(contains("mobility"))

offset_vector <- c()
for(i in countries)
{
  offset <- lagEstimation(i, TS1_matrix, TS2_matrix, windowsize=20)
  offset_vector <- c(offset_vector, offset)
}
names(offset_vector) <- countries
```
```{r}
lagInterpretation <- function(val, TS1Lag = "Mobility lag", TS2Lag = "Price lag")
{
  if(val > 20)
    res = c(Type = TS1Lag, Lag = val - 20 - 1)
  else
    res = c(Type = TS2Lag, Lag = val - 1)
  res  
}

offsets_df = sapply(offset_vector, lagInterpretation)
datatable(t(offsets_df))
```
4.3.1.1 Component A: Identify peaks and trough in each time series.
```{r}
library("ggpmisc")
## Define the search region
early_date <- rownames(combined_matrix_norm_s)[rownames(combined_matrix_norm_s) < "2020-08-01"]

## Write a wrapper function baed on the function find_peaks to identify the specific date where the peak occures. 
## For time series without a peak we take the maximum value instead. When writing a function, don't forget to select one ## time series and make sure it works for that before moving on.

selectPeakDate <- function(x)
{
  y <- ggpmisc:::find_peaks(x, span = 20)
  if(sum(y) == 0) 
    early_date[length(x)]
  else
    early_date[which(y)[1]]  
  
}

## Identify peaks and trough in each time series. 
early_peak <- apply(combined_matrix_norm_s[early_date, ], 2, selectPeakDate) %>% as.Date()
```

```{r}
early_arg_min <- apply(combined_matrix_norm_s[early_date, ], 2, function(x){early_date[which.min(x)]}) %>% as.Date()
```

Component B: Generate a vector of behaviour metrics that is a function of these peaks and troughs.
```{r}
## Select metric of interest
## BM1 = Peaks of the daily new cases.
covid_early_peak <- early_peak[grep("newCase", colnames(combined_matrix_norm_s))] %>% as.Date

## BM2 = Trough of the economics activities.
price_trough <- early_arg_min[grep("price", colnames(combined_matrix_norm_s))]%>% as.Date

## BM3 = Trough of the mobility
mobility_trough <- early_arg_min[grep("mobility", colnames(combined_matrix_norm_s))]%>% as.Date

## BM4 = Lag time between the peaks of the daily new cases and the bottom of the mobility movement.  
lag_covid <- mobility_trough - covid_early_peak
names(lag_covid) <- names(mobility_trough) <- names(price_trough) <- names(covid_early_peak) <- countries

## putting some of the information above into a data frame
df_turnpoint <- data.frame(covid_early_peak,
                           price_trough,
                           mobility_trough, 
                           lag_covid)
rownames(df_turnpoint) <- countries
```

4.3.2 Part 2: Define a distance to quantify the closeness of two countries.
```{r}
date_dist <- function(x, y) {
      sum(abs(as.numeric(x - y)))
}

## write double for-loop to calcualte the distance 
turnpoint_dist <- matrix(NA, 
                         nrow = nrow(df_turnpoint),
                         ncol = nrow(df_turnpoint),
                         dimnames = list(rownames(df_turnpoint),
                                             rownames(df_turnpoint)))
 for (i in 1:nrow(turnpoint_dist)) {
      for (j in 1:nrow(turnpoint_dist)) {
        turnpoint_dist[i, j] <- turnpoint_dist[j, i] <- date_dist(df_turnpoint[i, ], df_turnpoint[j, ])
      }
    }
```

4.3.3 Part 3: Cluster the countries based on your behaviour metric
```{r}
hclust_turnpoint <- hclust(as.dist(turnpoint_dist))
plot(hclust_turnpoint)
```

```{r}
o <- hclust_turnpoint$order
pheatmap(turnpoint_dist[o, o],
         cluster_rows = FALSE,
         cluster_cols = FALSE)
```

